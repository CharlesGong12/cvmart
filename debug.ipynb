{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchsampler.optim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11034/2058965080.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchsampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSAM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchsampler.optim'"
     ]
    }
   ],
   "source": [
    "from torchsampler.optim import SAM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ultralytics/__init__.py\n"
     ]
    }
   ],
   "source": [
    "import ultralytics\n",
    "print(ultralytics.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "for i in range(100):\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    " \n",
    "pid = os.getpid()\n",
    "!kill -9 $pid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/opt/conda/lib/python3.7/site-packages/tensorrt']\n",
      "8.5.1.7\n"
     ]
    }
   ],
   "source": [
    "import tensorrt as trt\n",
    "print(trt.__path__)\n",
    "print(trt.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.0.conv.weight: torch.Size([48, 3, 3, 3])\n",
      "model.0.bn.weight: torch.Size([48])\n",
      "model.0.bn.bias: torch.Size([48])\n",
      "model.1.conv.weight: torch.Size([96, 48, 3, 3])\n",
      "model.1.bn.weight: torch.Size([96])\n",
      "model.1.bn.bias: torch.Size([96])\n",
      "model.2.cv1.conv.weight: torch.Size([96, 96, 1, 1])\n",
      "model.2.cv1.bn.weight: torch.Size([96])\n",
      "model.2.cv1.bn.bias: torch.Size([96])\n",
      "model.2.cv2.conv.weight: torch.Size([96, 192, 1, 1])\n",
      "model.2.cv2.bn.weight: torch.Size([96])\n",
      "model.2.cv2.bn.bias: torch.Size([96])\n",
      "model.2.m.0.cv1.conv.weight: torch.Size([48, 48, 3, 3])\n",
      "model.2.m.0.cv1.bn.weight: torch.Size([48])\n",
      "model.2.m.0.cv1.bn.bias: torch.Size([48])\n",
      "model.2.m.0.cv2.conv.weight: torch.Size([48, 48, 3, 3])\n",
      "model.2.m.0.cv2.bn.weight: torch.Size([48])\n",
      "model.2.m.0.cv2.bn.bias: torch.Size([48])\n",
      "model.2.m.1.cv1.conv.weight: torch.Size([48, 48, 3, 3])\n",
      "model.2.m.1.cv1.bn.weight: torch.Size([48])\n",
      "model.2.m.1.cv1.bn.bias: torch.Size([48])\n",
      "model.2.m.1.cv2.conv.weight: torch.Size([48, 48, 3, 3])\n",
      "model.2.m.1.cv2.bn.weight: torch.Size([48])\n",
      "model.2.m.1.cv2.bn.bias: torch.Size([48])\n",
      "model.3.conv.weight: torch.Size([192, 96, 3, 3])\n",
      "model.3.bn.weight: torch.Size([192])\n",
      "model.3.bn.bias: torch.Size([192])\n",
      "model.4.cv1.conv.weight: torch.Size([192, 192, 1, 1])\n",
      "model.4.cv1.bn.weight: torch.Size([192])\n",
      "model.4.cv1.bn.bias: torch.Size([192])\n",
      "model.4.cv2.conv.weight: torch.Size([192, 576, 1, 1])\n",
      "model.4.cv2.bn.weight: torch.Size([192])\n",
      "model.4.cv2.bn.bias: torch.Size([192])\n",
      "model.4.m.0.cv1.conv.weight: torch.Size([96, 96, 3, 3])\n",
      "model.4.m.0.cv1.bn.weight: torch.Size([96])\n",
      "model.4.m.0.cv1.bn.bias: torch.Size([96])\n",
      "model.4.m.0.cv2.conv.weight: torch.Size([96, 96, 3, 3])\n",
      "model.4.m.0.cv2.bn.weight: torch.Size([96])\n",
      "model.4.m.0.cv2.bn.bias: torch.Size([96])\n",
      "model.4.m.1.cv1.conv.weight: torch.Size([96, 96, 3, 3])\n",
      "model.4.m.1.cv1.bn.weight: torch.Size([96])\n",
      "model.4.m.1.cv1.bn.bias: torch.Size([96])\n",
      "model.4.m.1.cv2.conv.weight: torch.Size([96, 96, 3, 3])\n",
      "model.4.m.1.cv2.bn.weight: torch.Size([96])\n",
      "model.4.m.1.cv2.bn.bias: torch.Size([96])\n",
      "model.4.m.2.cv1.conv.weight: torch.Size([96, 96, 3, 3])\n",
      "model.4.m.2.cv1.bn.weight: torch.Size([96])\n",
      "model.4.m.2.cv1.bn.bias: torch.Size([96])\n",
      "model.4.m.2.cv2.conv.weight: torch.Size([96, 96, 3, 3])\n",
      "model.4.m.2.cv2.bn.weight: torch.Size([96])\n",
      "model.4.m.2.cv2.bn.bias: torch.Size([96])\n",
      "model.4.m.3.cv1.conv.weight: torch.Size([96, 96, 3, 3])\n",
      "model.4.m.3.cv1.bn.weight: torch.Size([96])\n",
      "model.4.m.3.cv1.bn.bias: torch.Size([96])\n",
      "model.4.m.3.cv2.conv.weight: torch.Size([96, 96, 3, 3])\n",
      "model.4.m.3.cv2.bn.weight: torch.Size([96])\n",
      "model.4.m.3.cv2.bn.bias: torch.Size([96])\n",
      "model.5.conv.weight: torch.Size([384, 192, 3, 3])\n",
      "model.5.bn.weight: torch.Size([384])\n",
      "model.5.bn.bias: torch.Size([384])\n",
      "model.6.cv1.conv.weight: torch.Size([384, 384, 1, 1])\n",
      "model.6.cv1.bn.weight: torch.Size([384])\n",
      "model.6.cv1.bn.bias: torch.Size([384])\n",
      "model.6.cv2.conv.weight: torch.Size([384, 1152, 1, 1])\n",
      "model.6.cv2.bn.weight: torch.Size([384])\n",
      "model.6.cv2.bn.bias: torch.Size([384])\n",
      "model.6.m.0.cv1.conv.weight: torch.Size([192, 192, 3, 3])\n",
      "model.6.m.0.cv1.bn.weight: torch.Size([192])\n",
      "model.6.m.0.cv1.bn.bias: torch.Size([192])\n",
      "model.6.m.0.cv2.conv.weight: torch.Size([192, 192, 3, 3])\n",
      "model.6.m.0.cv2.bn.weight: torch.Size([192])\n",
      "model.6.m.0.cv2.bn.bias: torch.Size([192])\n",
      "model.6.m.1.cv1.conv.weight: torch.Size([192, 192, 3, 3])\n",
      "model.6.m.1.cv1.bn.weight: torch.Size([192])\n",
      "model.6.m.1.cv1.bn.bias: torch.Size([192])\n",
      "model.6.m.1.cv2.conv.weight: torch.Size([192, 192, 3, 3])\n",
      "model.6.m.1.cv2.bn.weight: torch.Size([192])\n",
      "model.6.m.1.cv2.bn.bias: torch.Size([192])\n",
      "model.6.m.2.cv1.conv.weight: torch.Size([192, 192, 3, 3])\n",
      "model.6.m.2.cv1.bn.weight: torch.Size([192])\n",
      "model.6.m.2.cv1.bn.bias: torch.Size([192])\n",
      "model.6.m.2.cv2.conv.weight: torch.Size([192, 192, 3, 3])\n",
      "model.6.m.2.cv2.bn.weight: torch.Size([192])\n",
      "model.6.m.2.cv2.bn.bias: torch.Size([192])\n",
      "model.6.m.3.cv1.conv.weight: torch.Size([192, 192, 3, 3])\n",
      "model.6.m.3.cv1.bn.weight: torch.Size([192])\n",
      "model.6.m.3.cv1.bn.bias: torch.Size([192])\n",
      "model.6.m.3.cv2.conv.weight: torch.Size([192, 192, 3, 3])\n",
      "model.6.m.3.cv2.bn.weight: torch.Size([192])\n",
      "model.6.m.3.cv2.bn.bias: torch.Size([192])\n",
      "model.7.conv.weight: torch.Size([576, 384, 3, 3])\n",
      "model.7.bn.weight: torch.Size([576])\n",
      "model.7.bn.bias: torch.Size([576])\n",
      "model.8.cv1.conv.weight: torch.Size([576, 576, 1, 1])\n",
      "model.8.cv1.bn.weight: torch.Size([576])\n",
      "model.8.cv1.bn.bias: torch.Size([576])\n",
      "model.8.cv2.conv.weight: torch.Size([576, 1152, 1, 1])\n",
      "model.8.cv2.bn.weight: torch.Size([576])\n",
      "model.8.cv2.bn.bias: torch.Size([576])\n",
      "model.8.m.0.cv1.conv.weight: torch.Size([288, 288, 3, 3])\n",
      "model.8.m.0.cv1.bn.weight: torch.Size([288])\n",
      "model.8.m.0.cv1.bn.bias: torch.Size([288])\n",
      "model.8.m.0.cv2.conv.weight: torch.Size([288, 288, 3, 3])\n",
      "model.8.m.0.cv2.bn.weight: torch.Size([288])\n",
      "model.8.m.0.cv2.bn.bias: torch.Size([288])\n",
      "model.8.m.1.cv1.conv.weight: torch.Size([288, 288, 3, 3])\n",
      "model.8.m.1.cv1.bn.weight: torch.Size([288])\n",
      "model.8.m.1.cv1.bn.bias: torch.Size([288])\n",
      "model.8.m.1.cv2.conv.weight: torch.Size([288, 288, 3, 3])\n",
      "model.8.m.1.cv2.bn.weight: torch.Size([288])\n",
      "model.8.m.1.cv2.bn.bias: torch.Size([288])\n",
      "model.9.cv1.conv.weight: torch.Size([288, 576, 1, 1])\n",
      "model.9.cv1.bn.weight: torch.Size([288])\n",
      "model.9.cv1.bn.bias: torch.Size([288])\n",
      "model.9.cv2.conv.weight: torch.Size([576, 1152, 1, 1])\n",
      "model.9.cv2.bn.weight: torch.Size([576])\n",
      "model.9.cv2.bn.bias: torch.Size([576])\n",
      "model.12.cv1.conv.weight: torch.Size([384, 960, 1, 1])\n",
      "model.12.cv1.bn.weight: torch.Size([384])\n",
      "model.12.cv1.bn.bias: torch.Size([384])\n",
      "model.12.cv2.conv.weight: torch.Size([384, 768, 1, 1])\n",
      "model.12.cv2.bn.weight: torch.Size([384])\n",
      "model.12.cv2.bn.bias: torch.Size([384])\n",
      "model.12.m.0.cv1.conv.weight: torch.Size([192, 192, 3, 3])\n",
      "model.12.m.0.cv1.bn.weight: torch.Size([192])\n",
      "model.12.m.0.cv1.bn.bias: torch.Size([192])\n",
      "model.12.m.0.cv2.conv.weight: torch.Size([192, 192, 3, 3])\n",
      "model.12.m.0.cv2.bn.weight: torch.Size([192])\n",
      "model.12.m.0.cv2.bn.bias: torch.Size([192])\n",
      "model.12.m.1.cv1.conv.weight: torch.Size([192, 192, 3, 3])\n",
      "model.12.m.1.cv1.bn.weight: torch.Size([192])\n",
      "model.12.m.1.cv1.bn.bias: torch.Size([192])\n",
      "model.12.m.1.cv2.conv.weight: torch.Size([192, 192, 3, 3])\n",
      "model.12.m.1.cv2.bn.weight: torch.Size([192])\n",
      "model.12.m.1.cv2.bn.bias: torch.Size([192])\n",
      "model.15.cv1.conv.weight: torch.Size([192, 576, 1, 1])\n",
      "model.15.cv1.bn.weight: torch.Size([192])\n",
      "model.15.cv1.bn.bias: torch.Size([192])\n",
      "model.15.cv2.conv.weight: torch.Size([192, 384, 1, 1])\n",
      "model.15.cv2.bn.weight: torch.Size([192])\n",
      "model.15.cv2.bn.bias: torch.Size([192])\n",
      "model.15.m.0.cv1.conv.weight: torch.Size([96, 96, 3, 3])\n",
      "model.15.m.0.cv1.bn.weight: torch.Size([96])\n",
      "model.15.m.0.cv1.bn.bias: torch.Size([96])\n",
      "model.15.m.0.cv2.conv.weight: torch.Size([96, 96, 3, 3])\n",
      "model.15.m.0.cv2.bn.weight: torch.Size([96])\n",
      "model.15.m.0.cv2.bn.bias: torch.Size([96])\n",
      "model.15.m.1.cv1.conv.weight: torch.Size([96, 96, 3, 3])\n",
      "model.15.m.1.cv1.bn.weight: torch.Size([96])\n",
      "model.15.m.1.cv1.bn.bias: torch.Size([96])\n",
      "model.15.m.1.cv2.conv.weight: torch.Size([96, 96, 3, 3])\n",
      "model.15.m.1.cv2.bn.weight: torch.Size([96])\n",
      "model.15.m.1.cv2.bn.bias: torch.Size([96])\n",
      "model.16.conv.weight: torch.Size([192, 192, 3, 3])\n",
      "model.16.bn.weight: torch.Size([192])\n",
      "model.16.bn.bias: torch.Size([192])\n",
      "model.18.cv1.conv.weight: torch.Size([384, 576, 1, 1])\n",
      "model.18.cv1.bn.weight: torch.Size([384])\n",
      "model.18.cv1.bn.bias: torch.Size([384])\n",
      "model.18.cv2.conv.weight: torch.Size([384, 768, 1, 1])\n",
      "model.18.cv2.bn.weight: torch.Size([384])\n",
      "model.18.cv2.bn.bias: torch.Size([384])\n",
      "model.18.m.0.cv1.conv.weight: torch.Size([192, 192, 3, 3])\n",
      "model.18.m.0.cv1.bn.weight: torch.Size([192])\n",
      "model.18.m.0.cv1.bn.bias: torch.Size([192])\n",
      "model.18.m.0.cv2.conv.weight: torch.Size([192, 192, 3, 3])\n",
      "model.18.m.0.cv2.bn.weight: torch.Size([192])\n",
      "model.18.m.0.cv2.bn.bias: torch.Size([192])\n",
      "model.18.m.1.cv1.conv.weight: torch.Size([192, 192, 3, 3])\n",
      "model.18.m.1.cv1.bn.weight: torch.Size([192])\n",
      "model.18.m.1.cv1.bn.bias: torch.Size([192])\n",
      "model.18.m.1.cv2.conv.weight: torch.Size([192, 192, 3, 3])\n",
      "model.18.m.1.cv2.bn.weight: torch.Size([192])\n",
      "model.18.m.1.cv2.bn.bias: torch.Size([192])\n",
      "model.19.conv.weight: torch.Size([384, 384, 3, 3])\n",
      "model.19.bn.weight: torch.Size([384])\n",
      "model.19.bn.bias: torch.Size([384])\n",
      "model.21.cv1.conv.weight: torch.Size([576, 960, 1, 1])\n",
      "model.21.cv1.bn.weight: torch.Size([576])\n",
      "model.21.cv1.bn.bias: torch.Size([576])\n",
      "model.21.cv2.conv.weight: torch.Size([576, 1152, 1, 1])\n",
      "model.21.cv2.bn.weight: torch.Size([576])\n",
      "model.21.cv2.bn.bias: torch.Size([576])\n",
      "model.21.m.0.cv1.conv.weight: torch.Size([288, 288, 3, 3])\n",
      "model.21.m.0.cv1.bn.weight: torch.Size([288])\n",
      "model.21.m.0.cv1.bn.bias: torch.Size([288])\n",
      "model.21.m.0.cv2.conv.weight: torch.Size([288, 288, 3, 3])\n",
      "model.21.m.0.cv2.bn.weight: torch.Size([288])\n",
      "model.21.m.0.cv2.bn.bias: torch.Size([288])\n",
      "model.21.m.1.cv1.conv.weight: torch.Size([288, 288, 3, 3])\n",
      "model.21.m.1.cv1.bn.weight: torch.Size([288])\n",
      "model.21.m.1.cv1.bn.bias: torch.Size([288])\n",
      "model.21.m.1.cv2.conv.weight: torch.Size([288, 288, 3, 3])\n",
      "model.21.m.1.cv2.bn.weight: torch.Size([288])\n",
      "model.21.m.1.cv2.bn.bias: torch.Size([288])\n",
      "model.22.cv2.0.0.conv.weight: torch.Size([64, 192, 3, 3])\n",
      "model.22.cv2.0.0.bn.weight: torch.Size([64])\n",
      "model.22.cv2.0.0.bn.bias: torch.Size([64])\n",
      "model.22.cv2.0.1.conv.weight: torch.Size([64, 64, 3, 3])\n",
      "model.22.cv2.0.1.bn.weight: torch.Size([64])\n",
      "model.22.cv2.0.1.bn.bias: torch.Size([64])\n",
      "model.22.cv2.0.2.weight: torch.Size([64, 64, 1, 1])\n",
      "model.22.cv2.0.2.bias: torch.Size([64])\n",
      "model.22.cv2.1.0.conv.weight: torch.Size([64, 384, 3, 3])\n",
      "model.22.cv2.1.0.bn.weight: torch.Size([64])\n",
      "model.22.cv2.1.0.bn.bias: torch.Size([64])\n",
      "model.22.cv2.1.1.conv.weight: torch.Size([64, 64, 3, 3])\n",
      "model.22.cv2.1.1.bn.weight: torch.Size([64])\n",
      "model.22.cv2.1.1.bn.bias: torch.Size([64])\n",
      "model.22.cv2.1.2.weight: torch.Size([64, 64, 1, 1])\n",
      "model.22.cv2.1.2.bias: torch.Size([64])\n",
      "model.22.cv2.2.0.conv.weight: torch.Size([64, 576, 3, 3])\n",
      "model.22.cv2.2.0.bn.weight: torch.Size([64])\n",
      "model.22.cv2.2.0.bn.bias: torch.Size([64])\n",
      "model.22.cv2.2.1.conv.weight: torch.Size([64, 64, 3, 3])\n",
      "model.22.cv2.2.1.bn.weight: torch.Size([64])\n",
      "model.22.cv2.2.1.bn.bias: torch.Size([64])\n",
      "model.22.cv2.2.2.weight: torch.Size([64, 64, 1, 1])\n",
      "model.22.cv2.2.2.bias: torch.Size([64])\n",
      "model.22.cv3.0.0.conv.weight: torch.Size([192, 192, 3, 3])\n",
      "model.22.cv3.0.0.bn.weight: torch.Size([192])\n",
      "model.22.cv3.0.0.bn.bias: torch.Size([192])\n",
      "model.22.cv3.0.1.conv.weight: torch.Size([192, 192, 3, 3])\n",
      "model.22.cv3.0.1.bn.weight: torch.Size([192])\n",
      "model.22.cv3.0.1.bn.bias: torch.Size([192])\n",
      "model.22.cv3.0.2.weight: torch.Size([45, 192, 1, 1])\n",
      "model.22.cv3.0.2.bias: torch.Size([45])\n",
      "model.22.cv3.1.0.conv.weight: torch.Size([192, 384, 3, 3])\n",
      "model.22.cv3.1.0.bn.weight: torch.Size([192])\n",
      "model.22.cv3.1.0.bn.bias: torch.Size([192])\n",
      "model.22.cv3.1.1.conv.weight: torch.Size([192, 192, 3, 3])\n",
      "model.22.cv3.1.1.bn.weight: torch.Size([192])\n",
      "model.22.cv3.1.1.bn.bias: torch.Size([192])\n",
      "model.22.cv3.1.2.weight: torch.Size([45, 192, 1, 1])\n",
      "model.22.cv3.1.2.bias: torch.Size([45])\n",
      "model.22.cv3.2.0.conv.weight: torch.Size([192, 576, 3, 3])\n",
      "model.22.cv3.2.0.bn.weight: torch.Size([192])\n",
      "model.22.cv3.2.0.bn.bias: torch.Size([192])\n",
      "model.22.cv3.2.1.conv.weight: torch.Size([192, 192, 3, 3])\n",
      "model.22.cv3.2.1.bn.weight: torch.Size([192])\n",
      "model.22.cv3.2.1.bn.bias: torch.Size([192])\n",
      "model.22.cv3.2.2.weight: torch.Size([45, 192, 1, 1])\n",
      "model.22.cv3.2.2.bias: torch.Size([45])\n",
      "model.22.dfl.conv.weight: torch.Size([1, 16, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO('/project/train/models/yolov8m/train/weights/best.pt')\n",
    "for k, v in model.model.named_parameters():\n",
    "    print(f'{k}: {v.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Ultralytics YOLOv8.0.145 üöÄ Python-3.7.16 torch-1.11.0+cu113 CUDA:0 (Tesla T4, 14972MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25865815 parameters, 0 gradients\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/project/train/models/yolov8m/train/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 49, 8400) (296.9 MB)\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['nvidia-tensorrt'] not found, attempting AutoUpdate...\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m ‚ùå AutoUpdate skipped (offline)\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m export failure ‚ùå 6.0s: No module named 'tensorrt'\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorrt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/ultralytics/engine/exporter.py\u001b[0m in \u001b[0;36mexport_engine\u001b[0;34m(self, prefix)\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m             \u001b[0;32mimport\u001b[0m \u001b[0mtensorrt\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtrt\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorrt'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12508/3024946357.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0multralytics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/project/train/models/yolov8m/train/weights/best.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tensorrt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mexport\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_cfg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDEFAULT_CFG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mExporter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_callbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/ultralytics/engine/exporter.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_torchscript\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# TensorRT required before ONNX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0monnx\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mxml\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# OpenVINO requires ONNX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_onnx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/ultralytics/engine/exporter.py\u001b[0m in \u001b[0;36mouter_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{prefix} export failure ‚ùå {dt.t:.1f}s: {e}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mouter_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/ultralytics/engine/exporter.py\u001b[0m in \u001b[0;36mouter_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mProfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m             \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{prefix} export success ‚úÖ {dt.t:.1f}s, saved as '{f}' ({file_size(f):.1f} MB)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/ultralytics/engine/exporter.py\u001b[0m in \u001b[0;36mexport_engine\u001b[0;34m(self, prefix)\u001b[0m\n\u001b[1;32m    514\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mLINUX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m                 \u001b[0mcheck_requirements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nvidia-tensorrt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'-U --index-url https://pypi.ngc.nvidia.com'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             \u001b[0;32mimport\u001b[0m \u001b[0mtensorrt\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtrt\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0mcheck_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'7.0.0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhard\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# require tensorrt>=7.0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorrt'"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO('/project/train/models/yolov8m/train/weights/best.pt')\n",
    "model.export(format='tensorrt', device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_chinese_chars(text):\n",
    "    pattern =re.compile(r'[\\u4e00-\\u9fa5ÔºàÔºâ]|\\d+')\n",
    "    return re.sub(pattern, '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\n",
      "WARNING ‚ö†Ô∏è imgsz=[360, 640] must be multiple of max stride 32, updating to [384, 640]\n",
      "image 1/1 /home/data/2863/ZDStraffic_sign20231108_V4_train_street_102_268.jpg: 384x640 2 persons, 5 cars, 1 truck, 29.8ms\n",
      "Speed: 2.3ms preprocess, 29.8ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "WARNING ‚ö†Ô∏è 'Boxes.boxes' is deprecated. Use 'Boxes.data' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "boxes: tensor([[0.0000e+00, 6.1102e+02, 2.8184e+02, 9.1739e+02, 7.4656e-01, 2.0000e+00],\n",
      "        [9.2169e+02, 6.5116e+02, 1.0566e+03, 7.5713e+02, 7.0361e-01, 2.0000e+00],\n",
      "        [3.0807e+02, 6.4114e+02, 4.3067e+02, 6.9373e+02, 6.0340e-01, 2.0000e+00],\n",
      "        [8.0453e+02, 6.3999e+02, 9.0768e+02, 7.2383e+02, 4.5669e-01, 2.0000e+00],\n",
      "        [1.8535e+03, 5.4531e+02, 1.8940e+03, 6.5165e+02, 4.4832e-01, 0.0000e+00],\n",
      "        [1.7905e+03, 5.5464e+02, 1.8317e+03, 6.5330e+02, 4.1788e-01, 0.0000e+00],\n",
      "        [8.0396e+02, 6.3924e+02, 9.0758e+02, 7.2485e+02, 3.4579e-01, 7.0000e+00],\n",
      "        [9.0896e+02, 6.5090e+02, 9.5022e+02, 6.8755e+02, 3.2552e-01, 2.0000e+00]], device='cuda:0')\n",
      "cls: tensor([2., 2., 2., 2., 0., 0., 7., 2.], device='cuda:0')\n",
      "conf: tensor([0.7466, 0.7036, 0.6034, 0.4567, 0.4483, 0.4179, 0.3458, 0.3255], device='cuda:0')\n",
      "data: tensor([[0.0000e+00, 6.1102e+02, 2.8184e+02, 9.1739e+02, 7.4656e-01, 2.0000e+00],\n",
      "        [9.2169e+02, 6.5116e+02, 1.0566e+03, 7.5713e+02, 7.0361e-01, 2.0000e+00],\n",
      "        [3.0807e+02, 6.4114e+02, 4.3067e+02, 6.9373e+02, 6.0340e-01, 2.0000e+00],\n",
      "        [8.0453e+02, 6.3999e+02, 9.0768e+02, 7.2383e+02, 4.5669e-01, 2.0000e+00],\n",
      "        [1.8535e+03, 5.4531e+02, 1.8940e+03, 6.5165e+02, 4.4832e-01, 0.0000e+00],\n",
      "        [1.7905e+03, 5.5464e+02, 1.8317e+03, 6.5330e+02, 4.1788e-01, 0.0000e+00],\n",
      "        [8.0396e+02, 6.3924e+02, 9.0758e+02, 7.2485e+02, 3.4579e-01, 7.0000e+00],\n",
      "        [9.0896e+02, 6.5090e+02, 9.5022e+02, 6.8755e+02, 3.2552e-01, 2.0000e+00]], device='cuda:0')\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (1080, 1920)\n",
      "shape: torch.Size([8, 6])\n",
      "xywh: tensor([[ 140.9176,  764.2078,  281.8351,  306.3695],\n",
      "        [ 989.1224,  704.1454,  134.8583,  105.9668],\n",
      "        [ 369.3715,  667.4359,  122.6000,   52.5936],\n",
      "        [ 856.1051,  681.9092,  103.1483,   83.8348],\n",
      "        [1873.7688,  598.4797,   40.4612,  106.3356],\n",
      "        [1811.0739,  603.9706,   41.1877,   98.6627],\n",
      "        [ 855.7723,  682.0448,  103.6212,   85.6108],\n",
      "        [ 929.5922,  669.2267,   41.2552,   36.6475]], device='cuda:0')\n",
      "xywhn: tensor([[0.0734, 0.7076, 0.1468, 0.2837],\n",
      "        [0.5152, 0.6520, 0.0702, 0.0981],\n",
      "        [0.1924, 0.6180, 0.0639, 0.0487],\n",
      "        [0.4459, 0.6314, 0.0537, 0.0776],\n",
      "        [0.9759, 0.5541, 0.0211, 0.0985],\n",
      "        [0.9433, 0.5592, 0.0215, 0.0914],\n",
      "        [0.4457, 0.6315, 0.0540, 0.0793],\n",
      "        [0.4842, 0.6197, 0.0215, 0.0339]], device='cuda:0')\n",
      "xyxy: tensor([[   0.0000,  611.0231,  281.8351,  917.3926],\n",
      "        [ 921.6932,  651.1620, 1056.5515,  757.1288],\n",
      "        [ 308.0715,  641.1392,  430.6715,  693.7327],\n",
      "        [ 804.5310,  639.9918,  907.6793,  723.8267],\n",
      "        [1853.5382,  545.3119, 1893.9994,  651.6475],\n",
      "        [1790.4800,  554.6393, 1831.6677,  653.3020],\n",
      "        [ 803.9617,  639.2394,  907.5829,  724.8502],\n",
      "        [ 908.9646,  650.9030,  950.2198,  687.5505]], device='cuda:0')\n",
      "xyxyn: tensor([[0.0000, 0.5658, 0.1468, 0.8494],\n",
      "        [0.4800, 0.6029, 0.5503, 0.7010],\n",
      "        [0.1605, 0.5936, 0.2243, 0.6423],\n",
      "        [0.4190, 0.5926, 0.4727, 0.6702],\n",
      "        [0.9654, 0.5049, 0.9865, 0.6034],\n",
      "        [0.9325, 0.5136, 0.9540, 0.6049],\n",
      "        [0.4187, 0.5919, 0.4727, 0.6712],\n",
      "        [0.4734, 0.6027, 0.4949, 0.6366]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "model = YOLO('/project/train/models/yolov8m.pt')\n",
    "results = model.predict('/home/data/2863/ZDStraffic_sign20231108_V4_train_street_102_268.jpg',device='cuda',imgsz=[384,640])\n",
    "print(results[0].boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "921.69"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "9.2169e+02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: no_u_turn\n",
      "1: u_turn_allowed\n",
      "2: bus_lane\n",
      "3: motor_vehicle_lane\n",
      "4: motor_vehicle_movement\n",
      "5: combined_u_turn_and_left_turn_lane\n",
      "6: u_turn_lane\n",
      "7: combined_through_and_right_turn_lane\n",
      "8: combined_through_and_left_turn_lane\n",
      "9: through_lane\n",
      "10: left_turn_lane\n",
      "11: right_turn_lane\n",
      "12: pedestrian_crossing\n",
      "13: roundabout_traffic\n",
      "14: drive_on_the_left_side_of_the_median_strip\n",
      "15: drive_on_the_right_side_of_the_median_strip\n",
      "16: turn_left_or_right\n",
      "17: through_and_right_turn\n",
      "18: through_and_left_turn\n",
      "19: right_turn\n",
      "20: left_turn\n",
      "21: straight_ahead\n",
      "22: restricted_parking_area_lifted\n",
      "23: no_parking_area\n",
      "24: long_term_parking_restriction_lifted\n",
      "25: no_long_term_parking\n",
      "26: no_parking\n",
      "27: overtaking_allowed\n",
      "28: no_overtaking\n",
      "29: no_through_and_right_turn\n",
      "30: no_through_and_left_turn\n",
      "31: no_left_and_right_turn\n",
      "32: no_through\n",
      "33:  no_right_turn\n",
      "34: no_left_turn\n",
      "35: no_entry_for_freight_vehicles\n",
      "36: no_entry_for_motor_vehicles\n",
      "37: no_entry\n",
      "38: no_passage\n",
      "39: yield_to_oncoming_traffic\n",
      "40: slow_down_and_yield\n",
      "41: stop_and_yield\n",
      "42: no_entry_for_vehicles_transporting_dangerous_goods\n",
      "43: no_entry_for_large_passenger_vehicles\n",
      "44: other\n",
      "\"no_u_turn\",\n",
      "\"u_turn_allowed\",\n",
      "\"bus_lane\",\n",
      "\"motor_vehicle_lane\",\n",
      "\"motor_vehicle_movement\",\n",
      "\"combined_u_turn_and_left_turn_lane\",\n",
      "\"u_turn_lane\",\n",
      "\"combined_through_and_right_turn_lane\",\n",
      "\"combined_through_and_left_turn_lane\",\n",
      "\"through_lane\",\n",
      "\"left_turn_lane\",\n",
      "\"right_turn_lane\",\n",
      "\"pedestrian_crossing\",\n",
      "\"roundabout_traffic\",\n",
      "\"drive_on_the_left_side_of_the_median_strip\",\n",
      "\"drive_on_the_right_side_of_the_median_strip\",\n",
      "\"turn_left_or_right\",\n",
      "\"through_and_right_turn\",\n",
      "\"through_and_left_turn\",\n",
      "\"right_turn\",\n",
      "\"left_turn\",\n",
      "\"straight_ahead\",\n",
      "\"restricted_parking_area_lifted\",\n",
      "\"no_parking_area\",\n",
      "\"long_term_parking_restriction_lifted\",\n",
      "\"no_long_term_parking\",\n",
      "\"no_parking\",\n",
      "\"overtaking_allowed\",\n",
      "\"no_overtaking\",\n",
      "\"no_through_and_right_turn\",\n",
      "\"no_through_and_left_turn\",\n",
      "\"no_left_and_right_turn\",\n",
      "\"no_through\",\n",
      "\" no_right_turn\",\n",
      "\"no_left_turn\",\n",
      "\"no_entry_for_freight_vehicles\",\n",
      "\"no_entry_for_motor_vehicles\",\n",
      "\"no_entry\",\n",
      "\"no_passage\",\n",
      "\"yield_to_oncoming_traffic\",\n",
      "\"slow_down_and_yield\",\n",
      "\"stop_and_yield\",\n",
      "\"no_entry_for_vehicles_transporting_dangerous_goods\",\n",
      "\"no_entry_for_large_passenger_vehicles\",\n",
      "\"other\",\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "label_file = '/project//train/src_repo/categories.txt'\n",
    "\n",
    "label_mapping = {}\n",
    "\n",
    "with open(label_file, 'r') as file:\n",
    "    index = 0\n",
    "    for line in file:\n",
    "        if line!='\\n':\n",
    "            label = line.strip()\n",
    "            label = remove_chinese_chars(label)\n",
    "            label_mapping[label] = index\n",
    "            index += 1\n",
    "\n",
    "# ÊâìÂç∞Ê†áÁ≠æÊò†Â∞ÑÁªìÊûú\n",
    "for label, index in label_mapping.items():\n",
    "    print(f\"{index}: {label}\")\n",
    "\n",
    "for label,index in label_mapping.items():                                        \n",
    "    print(f'\"{label}\",')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /project/train/src_repo\n",
      "Contents of data_folder: ['ZDStraffic_sign20231108_V4_train_street_102_268.jpg', 'ZDStraffic_sign20231108_V4_train_street_102_268.xml', 'ZDStraffic_sign20231108_V4_train_street_10_110.jpg', 'ZDStraffic_sign20231108_V4_train_street_10_110.xml', 'ZDStraffic_sign20231108_V4_train_street_114_56.jpg', 'ZDStraffic_sign20231108_V4_train_street_114_56.xml', 'ZDStraffic_sign20231108_V4_train_street_1161_140.jpg', 'ZDStraffic_sign20231108_V4_train_street_1161_140.xml', 'ZDStraffic_sign20231108_V4_train_street_1197_176.jpg', 'ZDStraffic_sign20231108_V4_train_street_1197_176.xml', 'ZDStraffic_sign20231108_V4_train_street_1320_220.jpg', 'ZDStraffic_sign20231108_V4_train_street_1320_220.xml', 'ZDStraffic_sign20231108_V4_train_street_1350_15.jpg', 'ZDStraffic_sign20231108_V4_train_street_1350_15.xml', 'ZDStraffic_sign20231108_V4_train_street_188_445.jpg', 'ZDStraffic_sign20231108_V4_train_street_188_445.xml', 'ZDStraffic_sign20231108_V4_train_street_20_57.jpg', 'ZDStraffic_sign20231108_V4_train_street_20_57.xml', 'ZDStraffic_sign20231108_V4_train_street_216_13.jpg', 'ZDStraffic_sign20231108_V4_train_street_216_13.xml', 'ZDStraffic_sign20231108_V4_train_street_217_104.jpg', 'ZDStraffic_sign20231108_V4_train_street_217_104.xml', 'ZDStraffic_sign20231108_V4_train_street_21_1644.jpg', 'ZDStraffic_sign20231108_V4_train_street_21_1644.xml', 'ZDStraffic_sign20231108_V4_train_street_25_1867.jpg', 'ZDStraffic_sign20231108_V4_train_street_25_1867.xml', 'ZDStraffic_sign20231108_V4_train_street_271_62.jpg', 'ZDStraffic_sign20231108_V4_train_street_271_62.xml', 'ZDStraffic_sign20231108_V4_train_street_274_34.jpg', 'ZDStraffic_sign20231108_V4_train_street_274_34.xml', 'ZDStraffic_sign20231108_V4_train_street_28_163.jpg', 'ZDStraffic_sign20231108_V4_train_street_28_163.xml', 'ZDStraffic_sign20231108_V4_train_street_310_375.jpg', 'ZDStraffic_sign20231108_V4_train_street_310_375.xml', 'ZDStraffic_sign20231108_V4_train_street_315_214.jpg', 'ZDStraffic_sign20231108_V4_train_street_315_214.xml', 'ZDStraffic_sign20231108_V4_train_street_322_105.jpg', 'ZDStraffic_sign20231108_V4_train_street_322_105.xml', 'ZDStraffic_sign20231108_V4_train_street_325_109.jpg', 'ZDStraffic_sign20231108_V4_train_street_325_109.xml', 'ZDStraffic_sign20231108_V4_train_street_333_394.jpg', 'ZDStraffic_sign20231108_V4_train_street_333_394.xml', 'ZDStraffic_sign20231108_V4_train_street_34_174.jpg', 'ZDStraffic_sign20231108_V4_train_street_34_174.xml', 'ZDStraffic_sign20231108_V4_train_street_364_235.jpg', 'ZDStraffic_sign20231108_V4_train_street_364_235.xml', 'ZDStraffic_sign20231108_V4_train_street_369_274.jpg', 'ZDStraffic_sign20231108_V4_train_street_369_274.xml', 'ZDStraffic_sign20231108_V4_train_street_394_3.jpg', 'ZDStraffic_sign20231108_V4_train_street_394_3.xml', 'ZDStraffic_sign20231108_V4_train_street_398_90.jpg', 'ZDStraffic_sign20231108_V4_train_street_398_90.xml', 'ZDStraffic_sign20231108_V4_train_street_417_102.jpg', 'ZDStraffic_sign20231108_V4_train_street_417_102.xml', 'ZDStraffic_sign20231108_V4_train_street_41_2379.jpg', 'ZDStraffic_sign20231108_V4_train_street_41_2379.xml', 'ZDStraffic_sign20231108_V4_train_street_431_55.jpg', 'ZDStraffic_sign20231108_V4_train_street_431_55.xml', 'ZDStraffic_sign20231108_V4_train_street_45_2322.jpg', 'ZDStraffic_sign20231108_V4_train_street_45_2322.xml', 'ZDStraffic_sign20231108_V4_train_street_460_35.jpg', 'ZDStraffic_sign20231108_V4_train_street_460_35.xml', 'ZDStraffic_sign20231108_V4_train_street_498_82.jpg', 'ZDStraffic_sign20231108_V4_train_street_498_82.xml', 'ZDStraffic_sign20231108_V4_train_street_53_285.jpg', 'ZDStraffic_sign20231108_V4_train_street_53_285.xml', 'ZDStraffic_sign20231108_V4_train_street_548_50.jpg', 'ZDStraffic_sign20231108_V4_train_street_548_50.xml', 'ZDStraffic_sign20231108_V4_train_street_576_62.jpg', 'ZDStraffic_sign20231108_V4_train_street_576_62.xml', 'ZDStraffic_sign20231108_V4_train_street_589_37.jpg', 'ZDStraffic_sign20231108_V4_train_street_589_37.xml', 'ZDStraffic_sign20231108_V4_train_street_59_87 (2).jpg', 'ZDStraffic_sign20231108_V4_train_street_59_87 (2).xml', 'ZDStraffic_sign20231108_V4_train_street_602_1.jpg', 'ZDStraffic_sign20231108_V4_train_street_602_1.xml', 'ZDStraffic_sign20231108_V4_train_street_620_39.jpg', 'ZDStraffic_sign20231108_V4_train_street_620_39.xml', 'ZDStraffic_sign20231108_V4_train_street_702_40.jpg', 'ZDStraffic_sign20231108_V4_train_street_702_40.xml', 'ZDStraffic_sign20231108_V4_train_street_73_1156.jpg', 'ZDStraffic_sign20231108_V4_train_street_73_1156.xml', 'ZDStraffic_sign20231108_V4_train_street_7_262.jpg', 'ZDStraffic_sign20231108_V4_train_street_7_262.xml', 'ZDStraffic_sign20231108_V4_train_street_82_2061.jpg', 'ZDStraffic_sign20231108_V4_train_street_82_2061.xml', 'ZDStraffic_sign20231108_V4_train_street_831_111.jpg', 'ZDStraffic_sign20231108_V4_train_street_831_111.xml', 'ZDStraffic_sign20231108_V4_train_street_844_112.jpg', 'ZDStraffic_sign20231108_V4_train_street_844_112.xml', 'ZDStraffic_sign20231108_V4_train_street_852_95.jpg', 'ZDStraffic_sign20231108_V4_train_street_852_95.xml', 'ZDStraffic_sign20231108_V4_train_street_856_118.jpg', 'ZDStraffic_sign20231108_V4_train_street_856_118.xml', 'ZDStraffic_sign20231108_V4_train_street_871_63.jpg', 'ZDStraffic_sign20231108_V4_train_street_871_63.xml', 'ZDStraffic_sign20231108_V4_train_street_892_116.jpg', 'ZDStraffic_sign20231108_V4_train_street_892_116.xml', 'ZDStraffic_sign20231108_V4_train_street_915_53.jpg', 'ZDStraffic_sign20231108_V4_train_street_915_53.xml']\n",
      "Image files found: ['ZDStraffic_sign20231108_V4_train_street_102_268.jpg', 'ZDStraffic_sign20231108_V4_train_street_10_110.jpg', 'ZDStraffic_sign20231108_V4_train_street_114_56.jpg', 'ZDStraffic_sign20231108_V4_train_street_1161_140.jpg', 'ZDStraffic_sign20231108_V4_train_street_1197_176.jpg', 'ZDStraffic_sign20231108_V4_train_street_1320_220.jpg', 'ZDStraffic_sign20231108_V4_train_street_1350_15.jpg', 'ZDStraffic_sign20231108_V4_train_street_188_445.jpg', 'ZDStraffic_sign20231108_V4_train_street_20_57.jpg', 'ZDStraffic_sign20231108_V4_train_street_216_13.jpg', 'ZDStraffic_sign20231108_V4_train_street_217_104.jpg', 'ZDStraffic_sign20231108_V4_train_street_21_1644.jpg', 'ZDStraffic_sign20231108_V4_train_street_25_1867.jpg', 'ZDStraffic_sign20231108_V4_train_street_271_62.jpg', 'ZDStraffic_sign20231108_V4_train_street_274_34.jpg', 'ZDStraffic_sign20231108_V4_train_street_28_163.jpg', 'ZDStraffic_sign20231108_V4_train_street_310_375.jpg', 'ZDStraffic_sign20231108_V4_train_street_315_214.jpg', 'ZDStraffic_sign20231108_V4_train_street_322_105.jpg', 'ZDStraffic_sign20231108_V4_train_street_325_109.jpg', 'ZDStraffic_sign20231108_V4_train_street_333_394.jpg', 'ZDStraffic_sign20231108_V4_train_street_34_174.jpg', 'ZDStraffic_sign20231108_V4_train_street_364_235.jpg', 'ZDStraffic_sign20231108_V4_train_street_369_274.jpg', 'ZDStraffic_sign20231108_V4_train_street_394_3.jpg', 'ZDStraffic_sign20231108_V4_train_street_398_90.jpg', 'ZDStraffic_sign20231108_V4_train_street_417_102.jpg', 'ZDStraffic_sign20231108_V4_train_street_41_2379.jpg', 'ZDStraffic_sign20231108_V4_train_street_431_55.jpg', 'ZDStraffic_sign20231108_V4_train_street_45_2322.jpg', 'ZDStraffic_sign20231108_V4_train_street_460_35.jpg', 'ZDStraffic_sign20231108_V4_train_street_498_82.jpg', 'ZDStraffic_sign20231108_V4_train_street_53_285.jpg', 'ZDStraffic_sign20231108_V4_train_street_548_50.jpg', 'ZDStraffic_sign20231108_V4_train_street_576_62.jpg', 'ZDStraffic_sign20231108_V4_train_street_589_37.jpg', 'ZDStraffic_sign20231108_V4_train_street_59_87 (2).jpg', 'ZDStraffic_sign20231108_V4_train_street_602_1.jpg', 'ZDStraffic_sign20231108_V4_train_street_620_39.jpg', 'ZDStraffic_sign20231108_V4_train_street_702_40.jpg', 'ZDStraffic_sign20231108_V4_train_street_73_1156.jpg', 'ZDStraffic_sign20231108_V4_train_street_7_262.jpg', 'ZDStraffic_sign20231108_V4_train_street_82_2061.jpg', 'ZDStraffic_sign20231108_V4_train_street_831_111.jpg', 'ZDStraffic_sign20231108_V4_train_street_844_112.jpg', 'ZDStraffic_sign20231108_V4_train_street_852_95.jpg', 'ZDStraffic_sign20231108_V4_train_street_856_118.jpg', 'ZDStraffic_sign20231108_V4_train_street_871_63.jpg', 'ZDStraffic_sign20231108_V4_train_street_892_116.jpg', 'ZDStraffic_sign20231108_V4_train_street_915_53.jpg']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "data_folder = '/home/data/2863'\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "print(\"Contents of data_folder:\", os.listdir(data_folder))\n",
    "\n",
    "image_files = [file for file in os.listdir(data_folder) if file.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "print(\"Image files found:\", image_files)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
